{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N524BgPd7Y19"
   },
   "source": [
    "# Image Classification of Cars Using Convolutional Neural Network\n",
    "\n",
    "## Hyperparameter Tuning\n",
    "\n",
    "- Members:\n",
    "  - Rachel Filderman - raf2dh\n",
    "  - Jae Yoon Sung - js2yp\n",
    "  - Congxin (David) Xu - cx2rx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2M5vd1_RZzr"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChNDbEggJmfj"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import google.colab\n",
    "from sklearn.datasets import load_files \n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm # progress bar\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFl1vpmC_wor"
   },
   "source": [
    "## Connect Kaggle with Google Colab\n",
    "- https://github.com/Kaggle/kaggle-api#api-credentials\n",
    "- https://www.kaggle.com/general/74235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "7JXEMyQ_AMxy",
    "outputId": "2a06a9de-dcae-44a9-fa50-d16b6637eeab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ea569333-2138-4ef1-b970-856ec2fad15b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ea569333-2138-4ef1-b970-856ec2fad15b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle (1).json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"rachelfilderman\",\"key\":\"f6d87c0046fa69f3b377d5decee4e465\"}'}"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload your kaggle.json API file\n",
    "google.colab.files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPuCb6DAAWqt"
   },
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCP6dUaFD9Fj",
    "outputId": "73844dc7-199b-4bd2-c64a-2e2179df17b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzkaGqCpEtq2"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbwG0SPqD87e",
    "outputId": "1989349c-a460-497a-b2ff-903a13f73ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stanford-car-dataset-by-classes-folder.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d jutrera/stanford-car-dataset-by-classes-folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifAwLv6WC3Rr",
    "outputId": "8a980253-5fb0-4625-d283-ab8c989c8208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  stanford-car-dataset-by-classes-folder.zip\n",
      "replace kaggle/anno_test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace kaggle/anno_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "! unzip stanford-car-dataset-by-classes-folder.zip -d kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7c_FvvWKZEv"
   },
   "outputs": [],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHiDDkjScxo7"
   },
   "source": [
    "# DenseNet201 and Xception: Batch Size 32 with no DA (85.20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkpNLEdadQgG"
   },
   "source": [
    "## Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaHjnlBVgT4z"
   },
   "source": [
    "### Average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_memAU3dUGe"
   },
   "source": [
    "#### Momentum = 0, average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdhHBMxLgQB6",
    "outputId": "d6be03ab-260b-4c78-b25e-8f6fdf26c424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 files belonging to 196 classes.\n",
      "Found 8041 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDq238UwdotA",
    "outputId": "e6ed0821-828d-4de4-a7cb-2202938e4f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "255/255 [==============================] - 250s 917ms/step - loss: 5.6305 - accuracy: 0.0074 - val_loss: 85.3790 - val_accuracy: 0.0077\n",
      "Epoch 2/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 5.3282 - accuracy: 0.0083 - val_loss: 6.0302 - val_accuracy: 0.0126\n",
      "Epoch 3/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 5.1273 - accuracy: 0.0165 - val_loss: 5.2040 - val_accuracy: 0.0215\n",
      "Epoch 4/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 4.7923 - accuracy: 0.0305 - val_loss: 9.0283 - val_accuracy: 0.0155\n",
      "Epoch 5/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 4.2098 - accuracy: 0.0694 - val_loss: 6.3469 - val_accuracy: 0.0343\n",
      "Epoch 6/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 3.4566 - accuracy: 0.1469 - val_loss: 4.2022 - val_accuracy: 0.0931\n",
      "Epoch 7/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 2.6686 - accuracy: 0.2940 - val_loss: 4.4435 - val_accuracy: 0.1268\n",
      "Epoch 8/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 1.9657 - accuracy: 0.4564 - val_loss: 3.6307 - val_accuracy: 0.2134\n",
      "Epoch 9/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 1.3544 - accuracy: 0.6127 - val_loss: 2.9925 - val_accuracy: 0.3037\n",
      "Epoch 10/100\n",
      "255/255 [==============================] - 227s 889ms/step - loss: 0.9534 - accuracy: 0.7101 - val_loss: 2.5570 - val_accuracy: 0.3784\n",
      "Epoch 11/100\n",
      "255/255 [==============================] - 228s 890ms/step - loss: 0.6680 - accuracy: 0.7985 - val_loss: 3.3955 - val_accuracy: 0.2966\n",
      "Epoch 12/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.3013 - accuracy: 0.9187 - val_loss: 1.1237 - val_accuracy: 0.6915\n",
      "Epoch 13/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.1097 - accuracy: 0.9800 - val_loss: 1.1446 - val_accuracy: 0.6980\n",
      "Epoch 14/100\n",
      "255/255 [==============================] - 227s 890ms/step - loss: 0.0633 - accuracy: 0.9916 - val_loss: 1.0719 - val_accuracy: 0.7163\n",
      "Epoch 15/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0428 - accuracy: 0.9946 - val_loss: 1.0966 - val_accuracy: 0.7170\n",
      "Epoch 16/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0324 - accuracy: 0.9959 - val_loss: 1.1043 - val_accuracy: 0.7172\n",
      "Epoch 17/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0311 - accuracy: 0.9948 - val_loss: 1.0537 - val_accuracy: 0.7270\n",
      "Epoch 18/100\n",
      "255/255 [==============================] - 227s 890ms/step - loss: 0.0221 - accuracy: 0.9960 - val_loss: 1.0249 - val_accuracy: 0.7345\n",
      "Epoch 19/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0180 - accuracy: 0.9970 - val_loss: 1.2202 - val_accuracy: 0.6954\n",
      "Epoch 20/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0201 - accuracy: 0.9961 - val_loss: 1.1618 - val_accuracy: 0.7079\n",
      "Epoch 21/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 1.0973 - val_accuracy: 0.7284\n",
      "Epoch 22/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 1.0088 - val_accuracy: 0.7503\n",
      "Epoch 23/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 1.0032 - val_accuracy: 0.7518\n",
      "Epoch 24/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 1.0001 - val_accuracy: 0.7518\n",
      "Epoch 25/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 1.0027 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0064 - accuracy: 0.9971 - val_loss: 1.0006 - val_accuracy: 0.7482\n",
      "Epoch 27/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 1.0106 - val_accuracy: 0.7489\n",
      "Epoch 28/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 1.0133 - val_accuracy: 0.7493\n",
      "Epoch 29/100\n",
      "255/255 [==============================] - 228s 894ms/step - loss: 0.0054 - accuracy: 0.9971 - val_loss: 1.0058 - val_accuracy: 0.7515\n",
      "Epoch 30/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 1.0388 - val_accuracy: 0.7483\n",
      "Epoch 31/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 1.0082 - val_accuracy: 0.7539\n",
      "Epoch 32/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 1.0039 - val_accuracy: 0.7551\n",
      "Epoch 33/100\n",
      "255/255 [==============================] - 228s 894ms/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 1.0141 - val_accuracy: 0.7558\n",
      "Epoch 34/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.0060 - val_accuracy: 0.7576\n"
     ]
    }
   ],
   "source": [
    "#Clear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False)\n",
    "# Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False)\n",
    "\n",
    "# Adding Additional Layers\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGbfmv9QgffQ",
    "outputId": "77737e72-f784-4ea2-d8d7-2cd0e2b35a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 63s 246ms/step - loss: 1.0060 - accuracy: 0.7576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0059767961502075, 0.7576172351837158]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3Wx1_-DFBE-"
   },
   "source": [
    "accuracy: 0.7576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxurV_SDd0Wb"
   },
   "source": [
    "#### Momentum = 0.3, average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra0jGj8Ed0Wr",
    "outputId": "13a4586b-3b1e-4348-b8bd-1b97c83ac2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 files belonging to 196 classes.\n",
      "Found 8041 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9uqYUqwd0Ws",
    "outputId": "7828e10e-cc5f-443e-a17f-ac580d384abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "255/255 [==============================] - 248s 905ms/step - loss: 5.5266 - accuracy: 0.0094 - val_loss: 11.4877 - val_accuracy: 0.0112\n",
      "Epoch 2/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 5.1933 - accuracy: 0.0173 - val_loss: 10.9957 - val_accuracy: 0.0134\n",
      "Epoch 3/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 4.7024 - accuracy: 0.0366 - val_loss: 6.5935 - val_accuracy: 0.0282\n",
      "Epoch 4/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 4.0695 - accuracy: 0.0873 - val_loss: 4.4698 - val_accuracy: 0.0760\n",
      "Epoch 5/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 3.1537 - accuracy: 0.2017 - val_loss: 3.3431 - val_accuracy: 0.1916\n",
      "Epoch 6/100\n",
      "255/255 [==============================] - 229s 894ms/step - loss: 2.2222 - accuracy: 0.4025 - val_loss: 3.4649 - val_accuracy: 0.2045\n",
      "Epoch 7/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 1.4740 - accuracy: 0.5843 - val_loss: 2.6075 - val_accuracy: 0.3451\n",
      "Epoch 8/100\n",
      "255/255 [==============================] - 229s 894ms/step - loss: 0.9637 - accuracy: 0.7190 - val_loss: 2.5524 - val_accuracy: 0.3653\n",
      "Epoch 9/100\n",
      "255/255 [==============================] - 228s 890ms/step - loss: 0.6254 - accuracy: 0.8227 - val_loss: 2.7055 - val_accuracy: 0.3935\n",
      "Epoch 10/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.3599 - accuracy: 0.9051 - val_loss: 2.2182 - val_accuracy: 0.4579\n",
      "Epoch 11/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.2784 - accuracy: 0.9215 - val_loss: 1.5261 - val_accuracy: 0.6005\n",
      "Epoch 12/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.1060 - accuracy: 0.9792 - val_loss: 0.9894 - val_accuracy: 0.7329\n",
      "Epoch 13/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0405 - accuracy: 0.9949 - val_loss: 0.9265 - val_accuracy: 0.7524\n",
      "Epoch 14/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0253 - accuracy: 0.9967 - val_loss: 0.9468 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0215 - accuracy: 0.9970 - val_loss: 0.9344 - val_accuracy: 0.7526\n",
      "Epoch 16/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0166 - accuracy: 0.9976 - val_loss: 0.9293 - val_accuracy: 0.7559\n",
      "Epoch 17/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.9370 - val_accuracy: 0.7609\n",
      "Epoch 18/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.9150 - val_accuracy: 0.7686\n",
      "Epoch 19/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.9066 - val_accuracy: 0.7682\n",
      "Epoch 20/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.9234 - val_accuracy: 0.7636\n",
      "Epoch 21/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.9338 - val_accuracy: 0.7643\n",
      "Epoch 22/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.8751 - val_accuracy: 0.7794\n",
      "Epoch 23/100\n",
      "255/255 [==============================] - 229s 894ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.8702 - val_accuracy: 0.7819\n",
      "Epoch 24/100\n",
      "255/255 [==============================] - 229s 893ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.8699 - val_accuracy: 0.7815\n",
      "Epoch 25/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0045 - accuracy: 0.9977 - val_loss: 0.8707 - val_accuracy: 0.7817\n",
      "Epoch 26/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 0.0043 - accuracy: 0.9980 - val_loss: 0.8713 - val_accuracy: 0.7826\n",
      "Epoch 27/100\n",
      "255/255 [==============================] - 229s 894ms/step - loss: 0.0041 - accuracy: 0.9978 - val_loss: 0.8730 - val_accuracy: 0.7829\n",
      "Epoch 28/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 0.8728 - val_accuracy: 0.7831\n",
      "Epoch 29/100\n",
      "255/255 [==============================] - 229s 894ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.8757 - val_accuracy: 0.7830\n",
      "Epoch 30/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 0.8778 - val_accuracy: 0.7832\n",
      "Epoch 31/100\n",
      "255/255 [==============================] - 229s 897ms/step - loss: 0.0043 - accuracy: 0.9977 - val_loss: 0.8856 - val_accuracy: 0.7816\n",
      "Epoch 32/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 0.8860 - val_accuracy: 0.7824\n",
      "Epoch 33/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.8877 - val_accuracy: 0.7816\n",
      "Epoch 34/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 0.8843 - val_accuracy: 0.7826\n"
     ]
    }
   ],
   "source": [
    "#Clear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False)\n",
    "# Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False)\n",
    "\n",
    "# Adding Additional Layers\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0.3),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HorI06ZZd0Ws",
    "outputId": "2cc17a46-17b4-4e54-b899-aea3c48e214d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 63s 244ms/step - loss: 0.8843 - accuracy: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8842913508415222, 0.7826141119003296]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTUfQdKT7r8g"
   },
   "source": [
    "0.7826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOFaBiBqd2Yf"
   },
   "source": [
    "#### Momentum = 0.6, average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCMj207vd2Yg",
    "outputId": "c3bb8096-201a-45ed-b316-738c673690e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 files belonging to 196 classes.\n",
      "Found 8041 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xo2tXf7d2Yh",
    "outputId": "f9f0e01b-3501-4c9a-e22c-9c247bb32ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "255/255 [==============================] - 249s 907ms/step - loss: 5.5335 - accuracy: 0.0063 - val_loss: 31.9404 - val_accuracy: 0.0076\n",
      "Epoch 2/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 5.3286 - accuracy: 0.0122 - val_loss: 13.7061 - val_accuracy: 0.0117\n",
      "Epoch 3/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 5.1288 - accuracy: 0.0183 - val_loss: 13.6852 - val_accuracy: 0.0095\n",
      "Epoch 4/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 4.8212 - accuracy: 0.0297 - val_loss: 5.7507 - val_accuracy: 0.0312\n",
      "Epoch 5/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 4.2718 - accuracy: 0.0659 - val_loss: 10.5538 - val_accuracy: 0.0081\n",
      "Epoch 6/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 3.7872 - accuracy: 0.1163 - val_loss: 5.6987 - val_accuracy: 0.0642\n",
      "Epoch 7/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 2.9209 - accuracy: 0.2507 - val_loss: 3.6584 - val_accuracy: 0.1727\n",
      "Epoch 8/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 2.2205 - accuracy: 0.3980 - val_loss: 2.8702 - val_accuracy: 0.3077\n",
      "Epoch 9/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 1.5760 - accuracy: 0.5502 - val_loss: 2.7670 - val_accuracy: 0.3311\n",
      "Epoch 10/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 1.0981 - accuracy: 0.6812 - val_loss: 1.8841 - val_accuracy: 0.4960\n",
      "Epoch 11/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.7672 - accuracy: 0.7814 - val_loss: 2.0579 - val_accuracy: 0.4721\n",
      "Epoch 12/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.3666 - accuracy: 0.9039 - val_loss: 1.3061 - val_accuracy: 0.6545\n",
      "Epoch 13/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 0.1624 - accuracy: 0.9669 - val_loss: 1.2595 - val_accuracy: 0.6651\n",
      "Epoch 14/100\n",
      "255/255 [==============================] - 227s 889ms/step - loss: 0.1002 - accuracy: 0.9850 - val_loss: 1.2257 - val_accuracy: 0.6799\n",
      "Epoch 15/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0626 - accuracy: 0.9930 - val_loss: 1.2414 - val_accuracy: 0.6778\n",
      "Epoch 16/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 0.0421 - accuracy: 0.9949 - val_loss: 1.2023 - val_accuracy: 0.6947\n",
      "Epoch 17/100\n",
      "255/255 [==============================] - 230s 898ms/step - loss: 0.0351 - accuracy: 0.9963 - val_loss: 1.2317 - val_accuracy: 0.6871\n",
      "Epoch 18/100\n",
      "255/255 [==============================] - 230s 900ms/step - loss: 0.0291 - accuracy: 0.9971 - val_loss: 1.1879 - val_accuracy: 0.6988\n",
      "Epoch 19/100\n",
      "255/255 [==============================] - 231s 901ms/step - loss: 0.0251 - accuracy: 0.9963 - val_loss: 1.1979 - val_accuracy: 0.7014\n",
      "Epoch 20/100\n",
      "255/255 [==============================] - 231s 902ms/step - loss: 0.0205 - accuracy: 0.9966 - val_loss: 1.2181 - val_accuracy: 0.7004\n",
      "Epoch 21/100\n",
      "255/255 [==============================] - 231s 902ms/step - loss: 0.1480 - accuracy: 0.9570 - val_loss: 2.0047 - val_accuracy: 0.5615\n",
      "Epoch 22/100\n",
      "255/255 [==============================] - 231s 901ms/step - loss: 0.1462 - accuracy: 0.9645 - val_loss: 1.1245 - val_accuracy: 0.7147\n",
      "Epoch 23/100\n",
      "255/255 [==============================] - 231s 902ms/step - loss: 0.0454 - accuracy: 0.9951 - val_loss: 1.0999 - val_accuracy: 0.7225\n",
      "Epoch 24/100\n",
      "255/255 [==============================] - 231s 903ms/step - loss: 0.0303 - accuracy: 0.9955 - val_loss: 1.0980 - val_accuracy: 0.7274\n",
      "Epoch 25/100\n",
      "255/255 [==============================] - 231s 902ms/step - loss: 0.0220 - accuracy: 0.9978 - val_loss: 1.0992 - val_accuracy: 0.7265\n",
      "Epoch 26/100\n",
      "255/255 [==============================] - 231s 903ms/step - loss: 0.0202 - accuracy: 0.9965 - val_loss: 1.0994 - val_accuracy: 0.7257\n",
      "Epoch 27/100\n",
      "255/255 [==============================] - 231s 903ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 1.0979 - val_accuracy: 0.7300\n",
      "Epoch 28/100\n",
      "255/255 [==============================] - 231s 904ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 1.0936 - val_accuracy: 0.7320\n",
      "Epoch 29/100\n",
      "255/255 [==============================] - 231s 904ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 1.0931 - val_accuracy: 0.7321\n",
      "Epoch 30/100\n",
      "255/255 [==============================] - 230s 901ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 1.0945 - val_accuracy: 0.7345\n",
      "Epoch 31/100\n",
      "255/255 [==============================] - 230s 901ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 1.1054 - val_accuracy: 0.7306\n",
      "Epoch 32/100\n",
      "255/255 [==============================] - 230s 901ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 1.0949 - val_accuracy: 0.7347\n",
      "Epoch 33/100\n",
      "255/255 [==============================] - 230s 901ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.0977 - val_accuracy: 0.7368\n",
      "Epoch 34/100\n",
      "255/255 [==============================] - 231s 901ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 1.1000 - val_accuracy: 0.7336\n",
      "Epoch 35/100\n",
      "255/255 [==============================] - 231s 902ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 1.1089 - val_accuracy: 0.7344\n",
      "Epoch 36/100\n",
      "255/255 [==============================] - 231s 904ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 1.1161 - val_accuracy: 0.7339\n",
      "Epoch 37/100\n",
      "255/255 [==============================] - 231s 905ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 1.1072 - val_accuracy: 0.7346\n",
      "Epoch 38/100\n",
      "255/255 [==============================] - 232s 906ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 1.1216 - val_accuracy: 0.7346\n",
      "Epoch 39/100\n",
      "255/255 [==============================] - 229s 896ms/step - loss: 0.0078 - accuracy: 0.9967 - val_loss: 1.1200 - val_accuracy: 0.7356\n"
     ]
    }
   ],
   "source": [
    "#Clear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False)\n",
    "# Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False)\n",
    "\n",
    "# Adding Additional Layers\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0.6),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dutLP8STd2Yh",
    "outputId": "ba18d3bd-8647-4c68-c4f9-9a1e045aefdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 63s 246ms/step - loss: 1.1200 - accuracy: 0.7356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1199944019317627, 0.735605001449585]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_baIB-iNfsM-"
   },
   "source": [
    "0.7356"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nge78NrVd4A8"
   },
   "source": [
    "#### Momentum = 0.9, average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaAlGAhQd4A9",
    "outputId": "cf9cfcd2-663b-480e-e07c-1b75984e0c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 files belonging to 196 classes.\n",
      "Found 8041 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ztsg48A_d4A9",
    "outputId": "59e6cae7-2137-4952-f6ac-c676d0ee98c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 1s 0us/step\n",
      "Epoch 1/100\n",
      "255/255 [==============================] - 287s 908ms/step - loss: 5.6298 - accuracy: 0.0053 - val_loss: 1793.0713 - val_accuracy: 0.0056\n",
      "Epoch 2/100\n",
      "255/255 [==============================] - 226s 886ms/step - loss: 5.3831 - accuracy: 0.0110 - val_loss: 190.1516 - val_accuracy: 0.0083\n",
      "Epoch 3/100\n",
      "255/255 [==============================] - 227s 887ms/step - loss: 5.2918 - accuracy: 0.0104 - val_loss: 24.9427 - val_accuracy: 0.0080\n",
      "Epoch 4/100\n",
      "255/255 [==============================] - 227s 887ms/step - loss: 5.1765 - accuracy: 0.0169 - val_loss: 1340.4017 - val_accuracy: 0.0061\n",
      "Epoch 5/100\n",
      "255/255 [==============================] - 227s 888ms/step - loss: 5.0579 - accuracy: 0.0233 - val_loss: 5.4716 - val_accuracy: 0.0184\n",
      "Epoch 6/100\n",
      "255/255 [==============================] - 226s 886ms/step - loss: 4.9299 - accuracy: 0.0298 - val_loss: 10.1928 - val_accuracy: 0.0270\n",
      "Epoch 7/100\n",
      "255/255 [==============================] - 227s 887ms/step - loss: 4.7273 - accuracy: 0.0465 - val_loss: 55.6729 - val_accuracy: 0.0061\n",
      "Epoch 8/100\n",
      "255/255 [==============================] - 227s 887ms/step - loss: 4.6928 - accuracy: 0.0475 - val_loss: 7.7410 - val_accuracy: 0.0301\n",
      "Epoch 9/100\n",
      "255/255 [==============================] - 227s 888ms/step - loss: 4.2706 - accuracy: 0.0774 - val_loss: 5.2879 - val_accuracy: 0.0509\n",
      "Epoch 10/100\n",
      "255/255 [==============================] - 226s 885ms/step - loss: 3.9256 - accuracy: 0.1155 - val_loss: 6.7350 - val_accuracy: 0.0279\n",
      "Epoch 11/100\n",
      "255/255 [==============================] - 226s 885ms/step - loss: 3.5789 - accuracy: 0.1576 - val_loss: 3.9756 - val_accuracy: 0.1199\n",
      "Epoch 12/100\n",
      "255/255 [==============================] - 227s 888ms/step - loss: 2.8338 - accuracy: 0.2790 - val_loss: 3.5172 - val_accuracy: 0.1791\n",
      "Epoch 13/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 2.3385 - accuracy: 0.3842 - val_loss: 3.0066 - val_accuracy: 0.2719\n",
      "Epoch 14/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 1.9071 - accuracy: 0.4866 - val_loss: 3.0923 - val_accuracy: 0.2711\n",
      "Epoch 15/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 1.4786 - accuracy: 0.5982 - val_loss: 3.3455 - val_accuracy: 0.2404\n",
      "Epoch 16/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 1.0834 - accuracy: 0.7049 - val_loss: 2.4200 - val_accuracy: 0.4047\n",
      "Epoch 17/100\n",
      "255/255 [==============================] - 227s 889ms/step - loss: 0.7443 - accuracy: 0.8077 - val_loss: 2.5493 - val_accuracy: 0.3845\n",
      "Epoch 18/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.4804 - accuracy: 0.8935 - val_loss: 2.4163 - val_accuracy: 0.4194\n",
      "Epoch 19/100\n",
      "255/255 [==============================] - 228s 890ms/step - loss: 0.3086 - accuracy: 0.9436 - val_loss: 2.2105 - val_accuracy: 0.4757\n",
      "Epoch 20/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.2000 - accuracy: 0.9706 - val_loss: 2.1647 - val_accuracy: 0.4890\n",
      "Epoch 21/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.1373 - accuracy: 0.9827 - val_loss: 2.5239 - val_accuracy: 0.4432\n",
      "Epoch 22/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0950 - accuracy: 0.9866 - val_loss: 1.9786 - val_accuracy: 0.5663\n",
      "Epoch 23/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0378 - accuracy: 0.9979 - val_loss: 1.7917 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0315 - accuracy: 0.9981 - val_loss: 1.7962 - val_accuracy: 0.5774\n",
      "Epoch 25/100\n",
      "255/255 [==============================] - 228s 891ms/step - loss: 0.0280 - accuracy: 0.9977 - val_loss: 1.8066 - val_accuracy: 0.5773\n",
      "Epoch 26/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0228 - accuracy: 0.9972 - val_loss: 1.8032 - val_accuracy: 0.5758\n",
      "Epoch 27/100\n",
      "255/255 [==============================] - 228s 892ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 1.7983 - val_accuracy: 0.5770\n",
      "Epoch 28/100\n",
      "255/255 [==============================] - 229s 894ms/step - loss: 0.0204 - accuracy: 0.9973 - val_loss: 1.7930 - val_accuracy: 0.5800\n",
      "Epoch 29/100\n",
      "255/255 [==============================] - 229s 895ms/step - loss: 0.0175 - accuracy: 0.9974 - val_loss: 1.8083 - val_accuracy: 0.5804\n",
      "Epoch 30/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0173 - accuracy: 0.9973 - val_loss: 1.8140 - val_accuracy: 0.5809\n",
      "Epoch 31/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 1.8088 - val_accuracy: 0.5820\n",
      "Epoch 32/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 1.8128 - val_accuracy: 0.5810\n",
      "Epoch 33/100\n",
      "255/255 [==============================] - 228s 893ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 1.8393 - val_accuracy: 0.5824\n"
     ]
    }
   ],
   "source": [
    "#Clear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False)\n",
    "# Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False)\n",
    "\n",
    "# Adding Additional Layers\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0.9),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZeGOemid4A-",
    "outputId": "be16c903-3702-490a-8e99-1d32b5eac736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 63s 248ms/step - loss: 1.8393 - accuracy: 0.5824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8393220901489258, 0.5823902487754822]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUyS6KNAhP6e"
   },
   "source": [
    " 0.5824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPb-UM4Rerdi"
   },
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kXfuUTWerdm"
   },
   "source": [
    "#### Momentum = 0, max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUE_WgPferdn",
    "outputId": "4bb93f46-ea30-4009-e76c-ed3475118467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 files belonging to 196 classes.\n",
      "Found 8041 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMzPJNaherdo",
    "outputId": "986c62be-c61b-4213-856a-3269ba40adc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "255/255 [==============================] - 258s 928ms/step - loss: 8.4064 - accuracy: 0.0068 - val_loss: 76181976.0000 - val_accuracy: 0.0049\n",
      "Epoch 2/100\n",
      "255/255 [==============================] - 227s 889ms/step - loss: 7.4997 - accuracy: 0.0063 - val_loss: 1570.2446 - val_accuracy: 0.0061\n",
      "Epoch 3/100\n",
      "255/255 [==============================] - 227s 887ms/step - loss: 6.6610 - accuracy: 0.0067 - val_loss: 19.6475 - val_accuracy: 0.0058\n",
      "Epoch 4/100\n",
      "255/255 [==============================] - 227s 887ms/step - loss: 6.5141 - accuracy: 0.0052 - val_loss: 178.2088 - val_accuracy: 0.0055\n",
      "Epoch 5/100\n",
      "255/255 [==============================] - 226s 883ms/step - loss: 6.2950 - accuracy: 0.0055 - val_loss: 5.6525 - val_accuracy: 0.0091\n",
      "Epoch 6/100\n",
      "255/255 [==============================] - 226s 884ms/step - loss: 6.4691 - accuracy: 0.0067 - val_loss: 5.4114 - val_accuracy: 0.0056\n",
      "Epoch 7/100\n",
      "255/255 [==============================] - 226s 883ms/step - loss: 6.4767 - accuracy: 0.0092 - val_loss: 5.4601 - val_accuracy: 0.0060\n",
      "Epoch 8/100\n",
      "255/255 [==============================] - 225s 881ms/step - loss: 6.2296 - accuracy: 0.0099 - val_loss: 5.3572 - val_accuracy: 0.0053\n",
      "Epoch 9/100\n",
      "255/255 [==============================] - 226s 884ms/step - loss: 6.3489 - accuracy: 0.0050 - val_loss: 40.7154 - val_accuracy: 0.0034\n",
      "Epoch 10/100\n",
      "255/255 [==============================] - 226s 884ms/step - loss: 6.2303 - accuracy: 0.0065 - val_loss: 5.3052 - val_accuracy: 0.0057\n",
      "Epoch 11/100\n",
      "255/255 [==============================] - 226s 885ms/step - loss: 6.1074 - accuracy: 0.0086 - val_loss: 76.9647 - val_accuracy: 0.0066\n",
      "Epoch 12/100\n",
      "255/255 [==============================] - 226s 884ms/step - loss: 5.7556 - accuracy: 0.0100 - val_loss: 7.9550 - val_accuracy: 0.0077\n",
      "Epoch 13/100\n",
      "255/255 [==============================] - 226s 886ms/step - loss: 5.4594 - accuracy: 0.0077 - val_loss: 5.5168 - val_accuracy: 0.0099\n",
      "Epoch 14/100\n",
      "255/255 [==============================] - 226s 884ms/step - loss: 5.4028 - accuracy: 0.0109 - val_loss: 6.0559 - val_accuracy: 0.0109\n",
      "Epoch 15/100\n",
      "255/255 [==============================] - 225s 882ms/step - loss: 5.3873 - accuracy: 0.0117 - val_loss: 5.1821 - val_accuracy: 0.0103\n",
      "Epoch 16/100\n",
      "255/255 [==============================] - ETA: 0s - loss: 5.3886 - accuracy: 0.0118"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Set Up\n",
    "#model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False, pooling = 'max')\n",
    "\n",
    "#Clear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False, \n",
    "                                                pooling='max')\n",
    "# # Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False, \n",
    "#                                        pooling = 'max')\n",
    "\n",
    "# Adding Additional Layers\n",
    "#avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(model.output)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSpcoqiherdo"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-yhS7mCerdp"
   },
   "source": [
    "#### Momentum = 0.3, max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3OLMNgEerdq"
   },
   "outputs": [],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVgW0HhEerdq"
   },
   "outputs": [],
   "source": [
    "#Clear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False, \n",
    "                                                pooling=max)\n",
    "# # Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False, \n",
    "#                                        pooling = 'max')\n",
    "\n",
    "# Adding Additional Layers\n",
    "#avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0.3),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4S1Pnv5erdq"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB3w1w39erdr"
   },
   "source": [
    "#### Momentum = 0.6, max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lY3xr6auerdr"
   },
   "outputs": [],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsbTsW0cerds"
   },
   "outputs": [],
   "source": [
    "#NClear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False, \n",
    "                                                pooling=max)\n",
    "# # Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False, \n",
    "#                                        pooling = 'max')\n",
    "\n",
    "# Adding Additional Layers\n",
    "#avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0.6),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkS4KYDXerds"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv99aI82RuR6"
   },
   "source": [
    "#### Momentum = 0.9, max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PkaJkKzRuSK"
   },
   "outputs": [],
   "source": [
    "# Load Class Names\n",
    "names = pandas.read_csv('/content/kaggle/names.csv', header=None)\n",
    "class_names = names.values.flatten()\n",
    "\n",
    "data_dir = \"/content/kaggle/car_data/car_data\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, \n",
    "#   you will need to change these dimensions accordingly\n",
    "img_height = 224; \n",
    "img_width = 224;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + '/train',\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir+ '/test',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhV8pM26RuSK"
   },
   "outputs": [],
   "source": [
    "#NClear Session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model Set Up\n",
    "model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                include_top=False, \n",
    "                                                pooling=max)\n",
    "\n",
    "# # Model Set Up\n",
    "# model = tf.keras.applications.Xception(weights = 'imagenet', \n",
    "#                                        include_top = False, \n",
    "#                                        pooling = 'max')\n",
    "\n",
    "# Adding Additional Layers\n",
    "#avg = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
    "output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs = model.input, outputs = output)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "def lr_schedule(epoch):\n",
    "  lrate = 0.001\n",
    "  if epoch > 10:\n",
    "    lrate = 0.0005\n",
    "  if epoch > 20:\n",
    "    lrate = 0.0001\n",
    "  return lrate\n",
    "\n",
    "# Define the number of training layers\n",
    "for layer in model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Model Compile\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(beta_1=0.9),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Call back early stop and learning rate schedule\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 10,\n",
    "                                             restore_best_weights = False) \\\n",
    "            , tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)]\n",
    "\n",
    "# Fit the History\n",
    "history = model.fit(train_ds, \n",
    "                    validation_data = validation_ds,\n",
    "                    epochs = 100, \n",
    "                    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X86RcE8tRuSL"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.evaluate(validation_ds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL Final Project - Hyperparameter Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
