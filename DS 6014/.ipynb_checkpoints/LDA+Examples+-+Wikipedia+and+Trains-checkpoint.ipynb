{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA) Examples\n",
    "\n",
    "This notebook explores using LDA for pages in Wikipedia and for analyis of the narratives in train accident reports. These examples show how the LDA method is possible thanks to variational approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import wikipedia\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "\n",
    "# Set stop words\n",
    "stopWords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This preprocessing step just removes stopwords\n",
    "\n",
    "def preprocessor(text):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return (\" \").join([word for word in tokens if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LDA_wikipedia:\n",
    "    \"\"\"Creates a class for Latent Dirichlet Allocation using summaries from Wikipedia\n",
    "    Input:\n",
    "        title_list = list of titles for Wikipedia pages\n",
    "        N_topics = number of topics for LDA to produce\n",
    "        N_words = the number of words to show in a topic\n",
    "        new_title = title for a new page not in the training s\n",
    "    Methods:\n",
    "        Topics = Outputs the list of topics in the selected Wikipedia pages as a dataframe\n",
    "        Predict_Topics\n",
    "            Input: New titles for Wikipedia pages\n",
    "            Output: A dataframe with the probabilities for topics for each new page\"\"\"\n",
    "    \n",
    "    def __init__(self, title_list, N_topics=3, N_words = 10):\n",
    "        # initialize variables\n",
    "        self.title_list = title_list\n",
    "        self.N_topics = N_topics\n",
    "        self.N_words = N_words\n",
    "        # start with an empty corpus\n",
    "        self.corpus = list()\n",
    "    \n",
    "        # Get the summary pages for the given titles\n",
    "        # then preprocess\n",
    "        for title in self.title_list:\n",
    "            page = wikipedia.page(title)\n",
    "            self.corpus.append(preprocessor(page.summary))\n",
    "        \n",
    "        # Get the matrix of word counts for the pages\n",
    "        # this will be the input the the LDA\n",
    "        self.countVectorizer = CountVectorizer(stop_words='english')\n",
    "        self.termFrequency = self.countVectorizer.fit_transform(self.corpus)\n",
    "        self.Words = self.countVectorizer.get_feature_names()\n",
    "        \n",
    "    def Topics(self):\n",
    "        # Obtain the estimates for the LDA model \n",
    "        self.lda = LatentDirichletAllocation(n_components=self.N_topics)\n",
    "        self.lda.fit(self.termFrequency)\n",
    "        \n",
    "        # Obtain the list of the top N_words in the topics\n",
    "        topics = list()\n",
    "        for topic in self.lda.components_:\n",
    "            topics.append([self.Words[i] for i in topic.argsort()[:-self.N_words - 1:-1]])\n",
    "            \n",
    "        # Create a list of column names, Words, for the dataframe output\n",
    "        cols = list()\n",
    "        for i in range(self.N_words):\n",
    "            cols.append(\"Word \"+(str(i)))\n",
    "        \n",
    "        # Create a dataframe with the topic no. and the words in each topic \n",
    "        # output this dataframe\n",
    "        Topics_df = pd.DataFrame(topics, columns = cols)\n",
    "        Topics_df.index.name = \"Topics\"\n",
    "        return Topics_df  \n",
    "    \n",
    "    def Predict_Topics(self, new_title_list):\n",
    "        # Get the new titles for the new pages\n",
    "        # and the number of new pages \n",
    "        self.new_title_list = new_title_list\n",
    "        N_new_docs = len(new_title_list)\n",
    "        \n",
    "        # For each of the new titles get the summary page in Wikipedia\n",
    "        # then obtain the estimate probabilities for each of the topics\n",
    "        # discovered in the training set for each of the new pages\n",
    "        new_doc_topics = list()\n",
    "        for title in self.new_title_list:\n",
    "            new_page = wikipedia.page(title)\n",
    "            new_doc = preprocessor(new_page.summary)\n",
    "            new_doc_topics.append(self.lda.transform(self.countVectorizer.transform([new_doc])))\n",
    "            \n",
    "        # Recast the list of topic probabilities as an array of size number of no. pages X no. of topics\n",
    "        new_doc_topics = np.array(new_doc_topics).reshape(N_new_docs, self.N_topics)\n",
    "        # Create labels for the columns in the output dataframe\n",
    "        cols = list()\n",
    "        for i in range(self.N_topics):\n",
    "            cols.append(\"Topic \"+(str(i)))\n",
    "            \n",
    "        # Create the dataframe whose rows contain the topic probabilities for specific Wikipedia pages\n",
    "        New_Page_df = pd.DataFrame(new_doc_topics, columns = cols )\n",
    "        New_Page_df.insert(0, 'Page Name', self.new_title_list)\n",
    "        return New_Page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poe</td>\n",
       "      <td>novels</td>\n",
       "      <td>published</td>\n",
       "      <td>novel</td>\n",
       "      <td>greene</td>\n",
       "      <td>writer</td>\n",
       "      <td>american</td>\n",
       "      <td>works</td>\n",
       "      <td>literary</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woolf</td>\n",
       "      <td>work</td>\n",
       "      <td>dickens</td>\n",
       "      <td>london</td>\n",
       "      <td>social</td>\n",
       "      <td>literary</td>\n",
       "      <td>fiction</td>\n",
       "      <td>known</td>\n",
       "      <td>novels</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>published</td>\n",
       "      <td>novel</td>\n",
       "      <td>vonnegut</td>\n",
       "      <td>stories</td>\n",
       "      <td>short</td>\n",
       "      <td>novels</td>\n",
       "      <td>american</td>\n",
       "      <td>fitzgerald</td>\n",
       "      <td>literature</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0  Word 1     Word 2   Word 3  Word 4    Word 5    Word 6  \\\n",
       "Topics                                                                      \n",
       "0             poe  novels  published    novel  greene    writer  american   \n",
       "1           woolf    work    dickens   london  social  literary   fiction   \n",
       "2       published   novel   vonnegut  stories   short    novels  american   \n",
       "\n",
       "            Word 7      Word 8      Word 9  \n",
       "Topics                                      \n",
       "0            works    literary  literature  \n",
       "1            known      novels     english  \n",
       "2       fitzgerald  literature       works  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with famous authors\n",
    "\n",
    "authors = ['\"Charles Dickens\"', '\"Graham Greene\"', '\"Jane Eyre\"', '\"Jane Austen\"', '\"George Orwell\"',\n",
    "          '\"Charlotte Bronte\"', '\"Virginia Woolf\"', '\"Evelyn Waugh\"',\n",
    "           '\"Mark Twain\"', '\"Scott Fitzgerald\"','\"Ernest Hemingway\"', '\"William Faulkner\"', \n",
    "          '\"Kurt Vonnegut\"','\"Harper Lee\"', '\"Edgar Allen Poe\"', '\"John Steinbeck\"' ]\n",
    "\n",
    "# This is a small data set, so try 3 topics\n",
    "ld_authors = LDA_wikipedia(title_list = authors, N_topics =3)\n",
    "ld_authors.Topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Name</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Toni Morrison\"</td>\n",
       "      <td>0.625974</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.367068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Stephen King\"</td>\n",
       "      <td>0.573359</td>\n",
       "      <td>0.073148</td>\n",
       "      <td>0.353493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Page Name   Topic 0   Topic 1   Topic 2\n",
       "0  \"Toni Morrison\"  0.625974  0.006958  0.367068\n",
       "1   \"Stephen King\"  0.573359  0.073148  0.353493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how it does with two famous contemporary authors\n",
    "ld_authors.Predict_Topics(['\"Toni Morrison\"', '\"Stephen King\"'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Accident Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.',\n",
       " 'ENGINE 286 CAUGHT FIRE AT THE SPRINGFIELD, MA STATION DUE TO BEARINGS IN MAIN GENERATOR LET GO.',\n",
       " 'TRAIN NO.#4 WITH ENGS 83/11/90/44 AND 11 CARS DERAILED 2 DEADHEAD CARS, C/44834 AND C/9639, WHILE MAKING A SHOVING MOVE ONTO TRACK 28.  THE DERAILMENT WAS DUE TO HIGH BUFF FORCES CAUSED JACKKNIFING OFDEADHEADING AMFLEET CAR 44834 LOCATED DIRECTLY BEHIND ENGINES DUE TO EXCESSIVE AMPERAGE GENERATED BY FOUR P42 LOCOMOTIVES SHOVING TRAIN AGAINST AN APPROXIMATELY 15-POUND BRAKE REDUCTION.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accident narratives are in a json file\n",
    "# Read the JSON file with the narratives and convert to a list for the LDA analysis\n",
    "\n",
    "\n",
    "with open('TrainNarratives.txt') as json_file:  \n",
    "    Narrative_dict = json.load(json_file)\n",
    "    \n",
    "train_reports = list(Narrative_dict.values())\n",
    "    \n",
    "train_reports[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LDA_trains:\n",
    "    \"\"\"Creates a class for Latent Dirichlet Allocation using summaries from Wikipedia\n",
    "    Input:\n",
    "        reports = list of narratives from accident reports\n",
    "        N_topics = number of topics for LDA to produce\n",
    "        N_words = the number of words to show in a topic\n",
    "        new_report = narrative for a new accident report not in the training set\n",
    "    Methods:\n",
    "        Topics = output the list of topics in the selected narratives\n",
    "        Predict_Topics = Show the predicted probabilities for topics for a new accident narrative\n",
    "            Input: new narrative\n",
    "            \"\"\"\n",
    "    def __init__(self, reports, N_topics=3, N_words = 10):\n",
    "        # the narrative reports\n",
    "        self.reports = reports\n",
    "        # initialize variables\n",
    "        self.N_topics = N_topics\n",
    "        self.N_words = N_words\n",
    "        \n",
    "        # Get the word counts in the reports\n",
    "        self.countVectorizer = CountVectorizer(stop_words='english')\n",
    "        self.termFrequency = self.countVectorizer.fit_transform(self.reports)\n",
    "        self.Words = self.countVectorizer.get_feature_names()\n",
    "        \n",
    "    def Topics(self):\n",
    "                \n",
    "        # Obtain the estimates for the LDA model \n",
    "        self.lda = LatentDirichletAllocation(n_components=self.N_topics)\n",
    "        self.lda.fit(self.termFrequency)\n",
    "        \n",
    "        # Obtain the list of the top N_words in the topics\n",
    "        topics = list()\n",
    "        for topic in self.lda.components_:\n",
    "            topics.append([self.Words[i] for i in topic.argsort()[:-self.N_words - 1:-1]])\n",
    "            \n",
    "        # For each of the topics in the model add the top N_words the list of topics\n",
    "        ### Your code here\n",
    "        # Create column names for the output matrix\n",
    "        cols = list()\n",
    "        for i in range(self.N_words):\n",
    "            cols.append(\"Word \"+(str(i)))\n",
    "            \n",
    "        # Create a dataframe with the topic no. and the words in each topic \n",
    "        # output this dataframe \n",
    "        Topics_df = pd.DataFrame(topics, columns = cols)\n",
    "        Topics_df.index.name = \"Topics\"\n",
    "        return Topics_df\n",
    "    \n",
    "    def Predict_Topics(self, new_reports):\n",
    "        self.new_reports = new_reports\n",
    "        \n",
    "        # Get the list of new accident report narratives\n",
    "        # and the number of new narratives\n",
    "        N_new_reports = len(self.new_reports)\n",
    "        \n",
    "        # For each of the new narratives \n",
    "        # obtain the estimated probabilities for each of the topics\n",
    "        # in each of the new narratives as estimated by the LDA results\n",
    "        # on the training set \n",
    "        new_report_topics = list()\n",
    "        ### Your code here        \n",
    "        for report in self.new_reports:\n",
    "            new_report = report\n",
    "            new_report_topics.append(self.lda.transform(self.countVectorizer.transform([new_report])))\n",
    "        \n",
    "        # Recast the list of probabilities for topics as an array \n",
    "        # of size no. of new reports X no. of topics\n",
    "        new_report_topics = np.array(new_report_topics).reshape(N_new_reports, self.N_topics)\n",
    "        \n",
    "        # Create column names for the output dataframe\n",
    "        cols = list()\n",
    "        for i in range(self.N_topics):\n",
    "            cols.append(\"Topic \"+(str(i)))  \n",
    "        \n",
    "        # Create the dataframe whose rows contain topic probabilities for \n",
    "        # specificed narratives/reports\n",
    "        New_Reports_df = pd.DataFrame(new_report_topics, columns = cols)\n",
    "        New_Reports_df.insert(0, 'Topic Name', self.reports)        \n",
    "        \n",
    "        return New_Reports_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train = LDA_trains(reports = train_reports, N_topics = 10, N_words = 10)\n",
    "lda_train.reports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>damage</td>\n",
       "      <td>pantograph</td>\n",
       "      <td>struck</td>\n",
       "      <td>equipment</td>\n",
       "      <td>wire</td>\n",
       "      <td>engine</td>\n",
       "      <td>unit</td>\n",
       "      <td>crossing</td>\n",
       "      <td>causing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hump</td>\n",
       "      <td>humping</td>\n",
       "      <td>operations</td>\n",
       "      <td>retarder</td>\n",
       "      <td>couplers</td>\n",
       "      <td>humped</td>\n",
       "      <td>causing</td>\n",
       "      <td>bowl</td>\n",
       "      <td>derailment</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>emergency</td>\n",
       "      <td>went</td>\n",
       "      <td>crew</td>\n",
       "      <td>conductor</td>\n",
       "      <td>main</td>\n",
       "      <td>mp</td>\n",
       "      <td>traveling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>motor</td>\n",
       "      <td>locomotive</td>\n",
       "      <td>smoke</td>\n",
       "      <td>traction</td>\n",
       "      <td>station</td>\n",
       "      <td>reported</td>\n",
       "      <td>electric</td>\n",
       "      <td>engine</td>\n",
       "      <td>caught</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>rail</td>\n",
       "      <td>track</td>\n",
       "      <td>car</td>\n",
       "      <td>pulling</td>\n",
       "      <td>train</td>\n",
       "      <td>broken</td>\n",
       "      <td>loads</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cars</td>\n",
       "      <td>track</td>\n",
       "      <td>car</td>\n",
       "      <td>crew</td>\n",
       "      <td>derailed</td>\n",
       "      <td>end</td>\n",
       "      <td>cut</td>\n",
       "      <td>lead</td>\n",
       "      <td>shoving</td>\n",
       "      <td>yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>track</td>\n",
       "      <td>car</td>\n",
       "      <td>cars</td>\n",
       "      <td>crew</td>\n",
       "      <td>engineer</td>\n",
       "      <td>conductor</td>\n",
       "      <td>stop</td>\n",
       "      <td>end</td>\n",
       "      <td>derailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ns</td>\n",
       "      <td>fuel</td>\n",
       "      <td>gallons</td>\n",
       "      <td>released</td>\n",
       "      <td>units</td>\n",
       "      <td>diesel</td>\n",
       "      <td>spilled</td>\n",
       "      <td>gal</td>\n",
       "      <td>unit</td>\n",
       "      <td>derailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>switch</td>\n",
       "      <td>track</td>\n",
       "      <td>cars</td>\n",
       "      <td>derailed</td>\n",
       "      <td>yard</td>\n",
       "      <td>hazardous</td>\n",
       "      <td>materials</td>\n",
       "      <td>lined</td>\n",
       "      <td>crew</td>\n",
       "      <td>shoving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>track</td>\n",
       "      <td>cars</td>\n",
       "      <td>derailed</td>\n",
       "      <td>end</td>\n",
       "      <td>damage</td>\n",
       "      <td>lead</td>\n",
       "      <td>causing</td>\n",
       "      <td>cut</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0      Word 1      Word 2     Word 3     Word 4     Word 5  \\\n",
       "Topics                                                                      \n",
       "0          train      damage  pantograph     struck  equipment       wire   \n",
       "1           hump     humping  operations   retarder   couplers     humped   \n",
       "2          train    derailed        cars  emergency       went       crew   \n",
       "3          motor  locomotive       smoke   traction    station   reported   \n",
       "4       derailed        cars        rail      track        car    pulling   \n",
       "5           cars       track         car       crew   derailed        end   \n",
       "6          train       track         car       cars       crew   engineer   \n",
       "7             ns        fuel     gallons   released      units     diesel   \n",
       "8         switch       track        cars   derailed       yard  hazardous   \n",
       "9            car       track        cars   derailed        end     damage   \n",
       "\n",
       "           Word 6   Word 7      Word 8     Word 9  \n",
       "Topics                                             \n",
       "0          engine     unit    crossing    causing  \n",
       "1         causing     bowl  derailment     normal  \n",
       "2       conductor     main          mp  traveling  \n",
       "3        electric   engine      caught         pc  \n",
       "4           train   broken       loads       head  \n",
       "5             cut     lead     shoving       yard  \n",
       "6       conductor     stop         end   derailed  \n",
       "7         spilled      gal        unit   derailed  \n",
       "8       materials    lined        crew    shoving  \n",
       "9            lead  causing         cut       east  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.Topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-f2bce0ff2219>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPredict_Topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_reports\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-566f30a001bc>\u001b[0m in \u001b[0;36mPredict_Topics\u001b[1;34m(self, new_reports)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreports\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mnew_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mnew_report_topics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountVectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1245\u001b[1;33m                 \u001b[1;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1246\u001b[0m                 \"string object received.\")\n\u001b[0;32m   1247\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "lda_train.Predict_Topics(train_reports[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reports = train_reports[:3]\n",
    "new_reports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.',\n",
       " 'ENGINE 286 CAUGHT FIRE AT THE SPRINGFIELD, MA STATION DUE TO BEARINGS IN MAIN GENERATOR LET GO.',\n",
       " 'TRAIN NO.#4 WITH ENGS 83/11/90/44 AND 11 CARS DERAILED 2 DEADHEAD CARS, C/44834 AND C/9639, WHILE MAKING A SHOVING MOVE ONTO TRACK 28.  THE DERAILMENT WAS DUE TO HIGH BUFF FORCES CAUSED JACKKNIFING OFDEADHEADING AMFLEET CAR 44834 LOCATED DIRECTLY BEHIND ENGINES DUE TO EXCESSIVE AMPERAGE GENERATED BY FOUR P42 LOCOMOTIVES SHOVING TRAIN AGAINST AN APPROXIMATELY 15-POUND BRAKE REDUCTION.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reports[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
