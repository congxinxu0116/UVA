{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is code for Quadratic Discriminant Analysis\n",
    "# Written by William F Basener\n",
    "# University of Virginia, School of Data Science\n",
    "# For use in teaching Bayesian Machine Learning\n",
    "#\n",
    "# The code currently computes the maximum likelihood classification\n",
    "# Student is to add method to compute posterior probabilities and maximum probability classification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_gaussian_pdf(X, MU, SIGMA):\n",
    "    \"\"\"Code from Data Blog https://xavierbourretsicotte.github.io/MLE_Multivariate_Gaussian.html\n",
    "    Maximum Likelihood Estimator: Multivariate Gaussian Distribution\n",
    "        by Xavier Bourret Sicotte, Fri 22 June 2018\n",
    "    Returns the pdf of a multivariate Gaussian distribution\n",
    "     - X, MU are p x 1 vectors\n",
    "     - SIGMA is a p x p matrix\"\"\"\n",
    "    # Initialize and reshape\n",
    "    X = X.reshape(-1, 1)\n",
    "    MU = MU.reshape(-1, 1)\n",
    "    p, _ = SIGMA.shape\n",
    "\n",
    "    # Compute values\n",
    "    SIGMA_inv = np.linalg.inv(SIGMA)\n",
    "    denominator = np.sqrt((2 * np.pi) ** p * np.linalg.det(SIGMA))\n",
    "    exponent = -(1 / 2) * ((X - MU).T @ SIGMA_inv @ (X - MU))\n",
    "\n",
    "    # Return result\n",
    "    return float((1. / denominator) * np.exp(exponent))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QDA:\n",
    "    \"\"\"Creates a class for Quadratic Discriminant Analysis\n",
    "    Input:\n",
    "        fname = file name for a csv file, must have one column labeled \"class\" and the rest numeric data\n",
    "    Methods:\n",
    "        compute_probabilities = given an input observation computes the likelihood for each class and the GML class\n",
    "        compute_probabilities: given an input observation and prior probabilities,\n",
    "            computes the posterior probabilities for each class and most probable class\"\"\"\n",
    "\n",
    "    def __init__(self, fname):\n",
    "        # reads the data and computes the statistics needed for classification\n",
    "\n",
    "        # read the iris data as a Pandas data frame\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        # separate the class labels from the rest of the data\n",
    "        # we are assuming the column name with class labels is 'Class'\n",
    "        # and all other columns are numeric\n",
    "        self.data_labels = df.loc[:]['Class']\n",
    "        self.data = np.asarray(df.drop('Class', axis=1, inplace=False))\n",
    "\n",
    "        # get information about the dimensions the data\n",
    "        self.num_rows, self.num_cols = self.data.shape\n",
    "\n",
    "        # get the class names as an array of strings\n",
    "        self.class_names = np.unique(self.data_labels)\n",
    "\n",
    "        # determine number of observations in each class\n",
    "        self.num_obs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.num_obs[name] = sum(self.data_labels == name)\n",
    "\n",
    "        # compute the mean of each class\n",
    "        self.means = dict()\n",
    "        for name in self.class_names:\n",
    "            self.means[name] = np.mean(self.data[self.data_labels == name, :], 0)\n",
    "\n",
    "        # compute the covariance matrix of each class\n",
    "        self.covs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.covs[name] = np.cov(np.transpose(self.data[self.data_labels == name, :]))\n",
    "\n",
    "    def compute_likelihoods(self, x):\n",
    "        # compute and output the likelihood of each class and the maximum likelihood class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.covs[name])\n",
    "            idx = idx + 1\n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "\n",
    "        # print the predicted class and all class likelihoods\n",
    "        print('QDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('QDA Class Likelihoods:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(likelihoods[indices_sorted[idx]]))\n",
    "\n",
    "        # return the likelihoods\n",
    "        return likelihoods\n",
    "\n",
    "    def compute_probabilities(self, x, priors):\n",
    "        # compute and output the probability of each class and the maximum probability class\n",
    "        \n",
    "        #likelihoods = self.compute_likelihoods(x)\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.covs[name])\n",
    "            idx = idx + 1\n",
    "        \n",
    "        #Number of classes\n",
    "        Nclass = len(self.class_names)\n",
    "        \n",
    "        \n",
    "        #posterior probabilties: likelihood * prior / normalize\n",
    "        postprob = np.zeros(Nclass)\n",
    "        idx = 0\n",
    "        normalize = 0\n",
    "        for name in self.class_names:\n",
    "            proportion = likelihoods[idx] * priors[name]\n",
    "            postprob[idx] = proportion\n",
    "            normalize += proportion\n",
    "            idx = idx + 1\n",
    "        postprob = np.round(postprob / normalize,4)\n",
    "        # get the indices for sorting the posterior probabilities (in descending order)\n",
    "        indices_sorted = np.argsort(postprob)[::-1]\n",
    "        \n",
    "        \n",
    "        print('QDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('QDA Posterior Probabilities:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(postprob[indices_sorted[idx]]))\n",
    "\n",
    "        # return the posterior probabilities\n",
    "        return postprob\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the data file\n",
    "\n",
    "path = \n",
    "file = 'Exercise3.2_iris_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model and example data with uninformative prior\n",
    "\n",
    "model_qda = QDA(path+file)\n",
    "Iris_setosa_observation = [5.1, 3.5, 1.4, 0.2]\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "model_qda.compute_probabilities(Iris_setosa_observation, uninformative_priors)\n",
    "print(model_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# LDA Code\n",
    "\n",
    "def multivariate_gaussian_pdf(X, MU, SIGMA):\n",
    "    \"\"\"Code from Data Blog https://xavierbourretsicotte.github.io/MLE_Multivariate_Gaussian.html\n",
    "    Maximum Likelihood Estimator: Multivariate Gaussian Distribution\n",
    "        by Xavier Bourret Sicotte, Fri 22 June 2018\n",
    "    Returns the pdf of a multivariate Gaussian distribution\n",
    "     - X, MU are p x 1 vectors\n",
    "     - SIGMA is a p x p matrix\"\"\"\n",
    "    # Initialize and reshape\n",
    "    X = X.reshape(-1, 1)\n",
    "    MU = MU.reshape(-1, 1)\n",
    "    p, _ = SIGMA.shape\n",
    "\n",
    "    # Compute values\n",
    "    SIGMA_inv = np.linalg.inv(SIGMA)\n",
    "    denominator = np.sqrt((2 * np.pi) ** p * np.linalg.det(SIGMA))\n",
    "    exponent = -(1 / 2) * ((X - MU).T @ SIGMA_inv @ (X - MU))\n",
    "\n",
    "    # Return result\n",
    "    return float((1. / denominator) * np.exp(exponent))\n",
    "\n",
    "\n",
    "class LDA:\n",
    "    \"\"\"Creates a class for Linear Discriminant Analysis\n",
    "    Input:\n",
    "        fname = file name for a csv file, must have one column labeled \"class\" and the rest numeric data\n",
    "    Methods:\n",
    "        compute_probabilities = given an input observation computes the likelihood for each class and the GML class\n",
    "        compute_probabilities: given an input observation and prior probabilities,\n",
    "            computes the posterior probabilities for each class and most probable class\"\"\"\n",
    "\n",
    "    def __init__(self, fname):\n",
    "        # reads the data and computes the statistics needed for classification\n",
    "\n",
    "        # read the iris data as a Pandas data frame\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        # separate the class labels from the rest of the data\n",
    "        # we are assuming the column name with class labels is 'Class'\n",
    "        # and all other columns are numeric\n",
    "        self.data_labels = df.loc[:]['Class']\n",
    "        self.data = np.asarray(df.drop('Class', axis=1, inplace=False))\n",
    "\n",
    "        # get information about the dimensions the data\n",
    "        self.num_rows, self.num_cols = self.data.shape\n",
    "\n",
    "        # get the class names as an array of strings\n",
    "        self.class_names = np.unique(self.data_labels)\n",
    "\n",
    "        # determine number of observations in each class\n",
    "        self.num_obs = dict()\n",
    "        for name in self.class_names:\n",
    "            self.num_obs[name] = sum(self.data_labels == name)\n",
    "\n",
    "        # compute the mean of each class\n",
    "        self.means = dict()\n",
    "        for name in self.class_names:\n",
    "            self.means[name] = np.mean(self.data[self.data_labels == name, :], 0)\n",
    "\n",
    "        # compute the mean covariance matrix\n",
    "        self.cov = np.zeros([self.num_cols, self.num_cols])\n",
    "        for name in self.class_names:\n",
    "            self.cov = self.cov + self.num_obs[name] * np.cov(np.transpose(self.data[self.data_labels == name, :]))\n",
    "        self.cov = self.cov / self.num_rows\n",
    "\n",
    "    def compute_likelihoods(self, x):\n",
    "        # compute and output the likelihood of each class and the maximum likelihood class\n",
    "\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.cov)\n",
    "            idx = idx + 1\n",
    "\n",
    "        # get the indices for sorting the likelihoods (in descending order)\n",
    "        indices_sorted = np.argsort(likelihoods)[::-1]\n",
    "\n",
    "        # print the predicted class and all class likelihoods\n",
    "        print('LDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('LDA Class Likelihoods:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(likelihoods[indices_sorted[idx]]))\n",
    "\n",
    "        # return the likelihoods\n",
    "        return likelihoods\n",
    "\n",
    "    def compute_probabilities(self, x, priors):\n",
    "        # compute and output the probability of each class and the maximum probability class\n",
    "        \n",
    "        #likelihoods = self.compute_likelihoods(x)\n",
    "        # check that the input data x has the correct number of rows\n",
    "        if not (len(x) == self.num_cols):\n",
    "            print('Data vector has wrong number of values.')\n",
    "            return -1\n",
    "\n",
    "        # reformat x as a numpy array, incase the user input a list\n",
    "        x = np.asarray(x)\n",
    "\n",
    "        # compute the likelihood of each class\n",
    "        likelihoods = np.zeros(len(self.class_names))\n",
    "        idx = 0\n",
    "        for name in self.class_names:\n",
    "            likelihoods[idx] = multivariate_gaussian_pdf(x, self.means[name], self.cov)\n",
    "            idx = idx + 1\n",
    "        \n",
    "        #Number of classes\n",
    "        Nclass = len(self.class_names)\n",
    "        \n",
    "        \n",
    "        #posterior probabilties: likelihood * prior / normalize\n",
    "        postprob = np.zeros(Nclass)\n",
    "        idx = 0\n",
    "        normalize = 0\n",
    "        for name in self.class_names:\n",
    "            proportion = likelihoods[idx] * priors[name]\n",
    "            postprob[idx] = proportion\n",
    "            normalize += proportion\n",
    "            idx = idx + 1\n",
    "        postprob = np.round(postprob / normalize, 4)\n",
    "        # get the indices for sorting the posterior probabilities (in descending order)\n",
    "        indices_sorted = np.argsort(postprob)[::-1]\n",
    "        \n",
    "        \n",
    "        print('LDA Predicted Class: ' + self.class_names[indices_sorted[0]])\n",
    "        print('LDA Posterior Probabilities:')\n",
    "        for idx in range(len(indices_sorted)):\n",
    "            print(self.class_names[indices_sorted[idx]] + ': ' + str(postprob[indices_sorted[idx]]))\n",
    "\n",
    "        # return the posterior probabilities\n",
    "        return postprob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The LDA model new data, uninformative prior\n",
    "\n",
    "model_lda = LDA(path+file)\n",
    "\n",
    "model_lda.compute_probabilities(Iris_setosa_observation, uninformative_priors)\n",
    "print(model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 1 & Uniform Priors: LDA\n",
    "model_lda = LDA(path+file)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "flower1 = [5.5, 2.4, 3.8, 1.1]\n",
    "\n",
    "model_lda.compute_probabilities(flower1, uninformative_priors)\n",
    "print(model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 2 & Uniform Priors: LDA\n",
    "model_lda = LDA(path+file)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "\n",
    "flower2 =  [5.5, 3.1, 5, 1.5]\n",
    "\n",
    "model_lda.compute_probabilities(flower2, uninformative_priors)\n",
    "print(model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 1 & Uniform Priors: QDA\n",
    "model_lda = QDA(path+file)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "flower1 = [5.5, 2.4, 3.8, 1.1]\n",
    "\n",
    "model_qda.compute_probabilities(flower1, uninformative_priors)\n",
    "print(model_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 2 & Uniform Priors: QDA\n",
    "model_lda = QDA(path+file)\n",
    "\n",
    "uninformative_priors = {\n",
    "    \"Iris-setosa\": 1 / 3,\n",
    "    \"Iris-versicolor\": 1 / 3,\n",
    "    \"Iris-virginica\": 1 / 3\n",
    "}\n",
    "flower1 = [5.5, 3.1, 5, 1.5]\n",
    "\n",
    "model_qda.compute_probabilities(flower2, uninformative_priors)\n",
    "print(model_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 1 & Informed Priors: LDA\n",
    "model_lda = LDA(path+file)\n",
    "\n",
    "inform_priors = {\n",
    "    \"Iris-setosa\": 0.1,\n",
    "    \"Iris-versicolor\": 0.2,\n",
    "    \"Iris-virginica\": 0.7\n",
    "}\n",
    "flower1 = [5.5, 2.4, 3.8, 1.1]\n",
    "\n",
    "model_lda.compute_probabilities(flower1, inform_priors)\n",
    "print(model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 2 & Informed Priors: LDA\n",
    "model_lda = LDA(path+file)\n",
    "\n",
    "inform_priors = {\n",
    "    \"Iris-setosa\": 0.1,\n",
    "    \"Iris-versicolor\": 0.2,\n",
    "    \"Iris-virginica\": 0.7\n",
    "}\n",
    "\n",
    "flower2 =  [5.5, 3.1, 5, 1.5]\n",
    "\n",
    "model_lda.compute_probabilities(flower2, inform_priors)\n",
    "print(model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 1 & Informed Priors: QDA\n",
    "model_lda = QDA(path+file)\n",
    "\n",
    "inform_priors = {\n",
    "    \"Iris-setosa\": 0.1,\n",
    "    \"Iris-versicolor\": 0.2,\n",
    "    \"Iris-virginica\": 0.7\n",
    "}\n",
    "flower1 = [5.5, 2.4, 3.8, 1.1]\n",
    "\n",
    "model_qda.compute_probabilities(flower1, inform_priors)\n",
    "print(model_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flower 2 & Informed Priors: QDA\n",
    "model_lda = QDA(path+file)\n",
    "\n",
    "inform_priors = {\n",
    "    \"Iris-setosa\": 0.1,\n",
    "    \"Iris-versicolor\": 0.2,\n",
    "    \"Iris-virginica\": 0.7\n",
    "}\n",
    "flower1 = [5.5, 3.1, 5, 1.5]\n",
    "\n",
    "model_qda.compute_probabilities(flower2, inform_priors)\n",
    "print(model_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
