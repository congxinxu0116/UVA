{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 3: How to Load, Convert, and Write JSON Files in Python\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "sys.tracebacklimit = 0 # turn off the error tracebacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "JSON and CSV are both text-based formats for the storage of data. It's possible to open either one in a plain text editor. Given this similarity, why does a CSV file usually take less memory than a JSON formatted file for the same data? Under what conditions could a JSON file be smaller in memory than a CSV file for the same data? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why does a CSV file usually take less memory than a JSON formatted file for the same data?\n",
    "    - Because we need a pair of key-value to represent 1 data point in a equivalent CSV file. The `key` will be a character string that is going to be replicated multiple times. That will take up a lot of memory. For example, in the JSON file provided in the link in Problem 2, we can see \"type\" and \"name\" repeatedly. In a CSV file, \"type\" and \"name\" will show up only once in the column names and that is it.\n",
    "- Under what conditions could a JSON file be smaller in memory than a CSV file for the same data?\n",
    "    - If we have a multi-layer nested JSON file with few key-value pairs under each nest, tabulating the same information in a CSV file will require more memory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "NASA has a dataset of all meteorites that have fallen to Earth between the years A.D. 860 and 2013. The data contain the name of each meteorite, along with the coordinates of the place where the meteorite hit, the mass of the meteorite, and the date of the collison. The data is stored as a JSON here: https://data.nasa.gov/resource/y77d-th95.json\n",
    "\n",
    "Look at the data in your web-browser and explain which strategy for loading the JSON into Python makes the most sense and why. \n",
    "\n",
    "Then write and run the code that will work for loading the data into Python. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>geolocation.type</th>\n",
       "      <th>geolocation.coordinates</th>\n",
       "      <th>:@computed_region_cbhk_fwbd</th>\n",
       "      <th>:@computed_region_nnqa_25f4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880-01-01T00:00:00.000</td>\n",
       "      <td>50.775000</td>\n",
       "      <td>6.083330</td>\n",
       "      <td>Point</td>\n",
       "      <td>[6.08333, 50.775]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951-01-01T00:00:00.000</td>\n",
       "      <td>56.183330</td>\n",
       "      <td>10.233330</td>\n",
       "      <td>Point</td>\n",
       "      <td>[10.23333, 56.18333]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abee</td>\n",
       "      <td>6</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1952-01-01T00:00:00.000</td>\n",
       "      <td>54.216670</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-113, 54.21667]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acapulco</td>\n",
       "      <td>10</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1976-01-01T00:00:00.000</td>\n",
       "      <td>16.883330</td>\n",
       "      <td>-99.900000</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-99.9, 16.88333]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achiras</td>\n",
       "      <td>370</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1902-01-01T00:00:00.000</td>\n",
       "      <td>-33.166670</td>\n",
       "      <td>-64.950000</td>\n",
       "      <td>Point</td>\n",
       "      <td>[-64.95, -33.16667]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   id nametype     recclass    mass  fall                     year  \\\n",
       "0    Aachen    1    Valid           L5      21  Fell  1880-01-01T00:00:00.000   \n",
       "1    Aarhus    2    Valid           H6     720  Fell  1951-01-01T00:00:00.000   \n",
       "2      Abee    6    Valid          EH4  107000  Fell  1952-01-01T00:00:00.000   \n",
       "3  Acapulco   10    Valid  Acapulcoite    1914  Fell  1976-01-01T00:00:00.000   \n",
       "4   Achiras  370    Valid           L6     780  Fell  1902-01-01T00:00:00.000   \n",
       "\n",
       "       reclat      reclong geolocation.type geolocation.coordinates  \\\n",
       "0   50.775000     6.083330            Point       [6.08333, 50.775]   \n",
       "1   56.183330    10.233330            Point    [10.23333, 56.18333]   \n",
       "2   54.216670  -113.000000            Point        [-113, 54.21667]   \n",
       "3   16.883330   -99.900000            Point       [-99.9, 16.88333]   \n",
       "4  -33.166670   -64.950000            Point     [-64.95, -33.16667]   \n",
       "\n",
       "  :@computed_region_cbhk_fwbd :@computed_region_nnqa_25f4  \n",
       "0                         NaN                         NaN  \n",
       "1                         NaN                         NaN  \n",
       "2                         NaN                         NaN  \n",
       "3                         NaN                         NaN  \n",
       "4                         NaN                         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = requests.get(\"https://data.nasa.gov/resource/y77d-th95.json\")\n",
    "tmp = json.loads(tmp.text)\n",
    "data2 = pd.json_normalize(tmp, max_level=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "The notebook for this module shows, as an example, how to pull data in JSON format from Reddit's top 25 posts on [/r/popular](https://www.reddit.com/r/popular/top/). The steps outlined there pull all of the features in the data into the dataframe, resulting in a dataframe with 172 columns. \n",
    "\n",
    "If we only wanted a few features, then looping across elements of the JSON list itself and extracting only the data we want may be a more efficient approach.\n",
    "\n",
    "Use looping - and not `pd.read_json()` or `pd.json_normalize()` - to create a dataframe with 25 rows (one for each of the top 25 posts), and only columns for `subreddit`, `title`, `ups`, and `created_utc`. The JSON file exists at http://www.reddit.com/r/popular/top.json, and don't forget to specify `headers = {'User-agent': 'DS6001'}` within `requests.get()`. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.reddit.com/r/popular/top.json'\n",
    "reddit = requests.get(url, headers = {'User-agent': 'DS6001'})\n",
    "reddit_json = json.loads(reddit.text)\n",
    "reddit_json = reddit_json['data']['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td>An interesting example of reinforcement learning</td>\n",
       "      <td>146973</td>\n",
       "      <td>1.600031e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>memes</td>\n",
       "      <td>Wait... I can get hit and not die?</td>\n",
       "      <td>122138</td>\n",
       "      <td>1.600077e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memes</td>\n",
       "      <td>Helicopter goes brrrr</td>\n",
       "      <td>134139</td>\n",
       "      <td>1.600091e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aww</td>\n",
       "      <td>Ninja Turtle</td>\n",
       "      <td>113605</td>\n",
       "      <td>1.600050e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pics</td>\n",
       "      <td>Our jellybean crop is coming in nicely this year</td>\n",
       "      <td>111868</td>\n",
       "      <td>1.600041e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>funny</td>\n",
       "      <td>Cat in a doll house</td>\n",
       "      <td>104594</td>\n",
       "      <td>1.600040e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>memes</td>\n",
       "      <td>Feeling old yet??</td>\n",
       "      <td>95986</td>\n",
       "      <td>1.600063e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>memes</td>\n",
       "      <td>My parent's rich bois</td>\n",
       "      <td>97001</td>\n",
       "      <td>1.600075e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TIHI</td>\n",
       "      <td>Thanks, I hate sex in the 19th century</td>\n",
       "      <td>93018</td>\n",
       "      <td>1.600031e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td>It's all about training and practising hard</td>\n",
       "      <td>95578</td>\n",
       "      <td>1.600083e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>memes</td>\n",
       "      <td>Pinks dissapointment is immesurable</td>\n",
       "      <td>90031</td>\n",
       "      <td>1.600068e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aww</td>\n",
       "      <td>Platform 9 3/4 to dogwartz</td>\n",
       "      <td>86798</td>\n",
       "      <td>1.600080e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pics</td>\n",
       "      <td>New work completed. Have a great week everyone!</td>\n",
       "      <td>93139</td>\n",
       "      <td>1.600088e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL that Ted Kaczynski (better known as the Un...</td>\n",
       "      <td>84511</td>\n",
       "      <td>1.600036e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dankmemes</td>\n",
       "      <td>Please, let me be a dinosaur</td>\n",
       "      <td>86773</td>\n",
       "      <td>1.600083e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>teenagers</td>\n",
       "      <td>College Life, here I come !</td>\n",
       "      <td>79051</td>\n",
       "      <td>1.600042e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>memes</td>\n",
       "      <td>A rebellion I can get behind</td>\n",
       "      <td>77989</td>\n",
       "      <td>1.600038e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>This Tibetan Cherry tree at my local park look...</td>\n",
       "      <td>77704</td>\n",
       "      <td>1.600048e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td>Listen to 3 year old's emergency call saves he...</td>\n",
       "      <td>77131</td>\n",
       "      <td>1.600039e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pics</td>\n",
       "      <td>This breast feeding mother was asked to cover ...</td>\n",
       "      <td>77793</td>\n",
       "      <td>1.600079e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PublicFreakout</td>\n",
       "      <td>Spin it out, out out out!</td>\n",
       "      <td>77048</td>\n",
       "      <td>1.600045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gaming</td>\n",
       "      <td>Daedric Gods</td>\n",
       "      <td>76747</td>\n",
       "      <td>1.600040e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dankmemes</td>\n",
       "      <td>Quite anticlamactic</td>\n",
       "      <td>76755</td>\n",
       "      <td>1.600069e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL of Martin Pistorius, a man who fell into a...</td>\n",
       "      <td>78743</td>\n",
       "      <td>1.600087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>funny</td>\n",
       "      <td>In our head it was spectacular</td>\n",
       "      <td>70977</td>\n",
       "      <td>1.600074e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddit                                              title  \\\n",
       "0   interestingasfuck   An interesting example of reinforcement learning   \n",
       "1               memes                 Wait... I can get hit and not die?   \n",
       "2               memes                              Helicopter goes brrrr   \n",
       "3                 aww                                       Ninja Turtle   \n",
       "4                pics   Our jellybean crop is coming in nicely this year   \n",
       "5               funny                                Cat in a doll house   \n",
       "6               memes                                  Feeling old yet??   \n",
       "7               memes                              My parent's rich bois   \n",
       "8                TIHI             Thanks, I hate sex in the 19th century   \n",
       "9    nextfuckinglevel        It's all about training and practising hard   \n",
       "10              memes                Pinks dissapointment is immesurable   \n",
       "11                aww                         Platform 9 3/4 to dogwartz   \n",
       "12               pics    New work completed. Have a great week everyone!   \n",
       "13      todayilearned  TIL that Ted Kaczynski (better known as the Un...   \n",
       "14          dankmemes                       Please, let me be a dinosaur   \n",
       "15          teenagers                        College Life, here I come !   \n",
       "16              memes                       A rebellion I can get behind   \n",
       "17  mildlyinteresting  This Tibetan Cherry tree at my local park look...   \n",
       "18   nextfuckinglevel  Listen to 3 year old's emergency call saves he...   \n",
       "19               pics  This breast feeding mother was asked to cover ...   \n",
       "20     PublicFreakout                          Spin it out, out out out!   \n",
       "21             gaming                                       Daedric Gods   \n",
       "22          dankmemes                                Quite anticlamactic   \n",
       "23      todayilearned  TIL of Martin Pistorius, a man who fell into a...   \n",
       "24              funny                     In our head it was spectacular   \n",
       "\n",
       "       ups   created_utc  \n",
       "0   146973  1.600031e+09  \n",
       "1   122138  1.600077e+09  \n",
       "2   134139  1.600091e+09  \n",
       "3   113605  1.600050e+09  \n",
       "4   111868  1.600041e+09  \n",
       "5   104594  1.600040e+09  \n",
       "6    95986  1.600063e+09  \n",
       "7    97001  1.600075e+09  \n",
       "8    93018  1.600031e+09  \n",
       "9    95578  1.600083e+09  \n",
       "10   90031  1.600068e+09  \n",
       "11   86798  1.600080e+09  \n",
       "12   93139  1.600088e+09  \n",
       "13   84511  1.600036e+09  \n",
       "14   86773  1.600083e+09  \n",
       "15   79051  1.600042e+09  \n",
       "16   77989  1.600038e+09  \n",
       "17   77704  1.600048e+09  \n",
       "18   77131  1.600039e+09  \n",
       "19   77793  1.600079e+09  \n",
       "20   77048  1.600045e+09  \n",
       "21   76747  1.600040e+09  \n",
       "22   76755  1.600069e+09  \n",
       "23   78743  1.600087e+09  \n",
       "24   70977  1.600074e+09  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.DataFrame(\n",
    "    [u['data']['subreddit'], \\\n",
    "     u['data']['title'], \\\n",
    "     u['data']['ups'],  \\\n",
    "     u['data']['created_utc']] for u in reddit_json\n",
    ")\n",
    "users_df.columns = ['subreddit', 'title', 'ups', 'created_utc']\n",
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "The NBA has saved data on all 30 teams' shooting statistics for the 2014-2015 season here: https://stats.nba.com/js/data/sportvu/2015/shootingTeamData.json. Take a moment and look at this JSON file in your web browser. The structure of this particular JSON is complicated, but see if you can find the team-by-team data. In this problem our goal is to use `pd.json_normalize()` to get the data into a dataframe. The following questions will guide you towards this goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "Download the raw text of the NBA JSON file and register it as JSON formatted data in Python's memory. (2 points)\n",
    "\n",
    "### Part b\n",
    "Describe, in words, the path that leads to the team-by-team data. (2 points)\n",
    "\n",
    "### Part c\n",
    "Use the `pd.json_normalize()` function to pull the team-by-team data into a dataframe. This is going to be tricky. You will need to use indexing on the JSON data as well as the `record_path` parameter. \n",
    "\n",
    "If you are successful, you will have a dataframe with 30 rows and 33 columns. The first row will refer to the Golden State Warriors, the second row will refer to the San Antonio Spurs, and the third row will refer to the Cleveland Cavaliers. The columns will only be named 0, 1, 2, ... at this point. (4 points)\n",
    "\n",
    "### Part d\n",
    "Find the path that leads to the headers (the column names), and extract these names as a list. Then set the `.columns` attribute of the dataframe you created in part c equal to this list. The result should be that the dataframe now has the correct column names. (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "Save the NBA dataframe you extracted in problem 4 as a JSON-formatted text file on your local machine. Format the JSON so that it is organized as dictionary with three lists: `columns` lists the column names, `index` lists the row names, and `data` is a list-of-lists of data points, one list for each row. (Hint: this is possible with one line of code) (2 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
