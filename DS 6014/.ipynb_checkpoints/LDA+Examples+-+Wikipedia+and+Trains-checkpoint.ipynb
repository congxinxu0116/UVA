{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA) Examples\n",
    "\n",
    "This notebook explores using LDA for pages in Wikipedia and for analyis of the narratives in train accident reports. These examples show how the LDA method is possible thanks to variational approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import wikipedia\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "\n",
    "# Set stop words\n",
    "stopWords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This preprocessing step just removes stopwords\n",
    "\n",
    "def preprocessor(text):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return (\" \").join([word for word in tokens if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LDA_wikipedia:\n",
    "    \"\"\"Creates a class for Latent Dirichlet Allocation using summaries from Wikipedia\n",
    "    Input:\n",
    "        title_list = list of titles for Wikipedia pages\n",
    "        N_topics = number of topics for LDA to produce\n",
    "        N_words = the number of words to show in a topic\n",
    "        new_title = title for a new page not in the training s\n",
    "    Methods:\n",
    "        Topics = Outputs the list of topics in the selected Wikipedia pages as a dataframe\n",
    "        Predict_Topics\n",
    "            Input: New titles for Wikipedia pages\n",
    "            Output: A dataframe with the probabilities for topics for each new page\"\"\"\n",
    "    \n",
    "    def __init__(self, title_list, N_topics=3, N_words = 10):\n",
    "        # initialize variables\n",
    "        self.title_list = title_list\n",
    "        self.N_topics = N_topics\n",
    "        self.N_words = N_words\n",
    "        # start with an empty corpus\n",
    "        self.corpus = list()\n",
    "    \n",
    "        # Get the summary pages for the given titles\n",
    "        # then preprocess\n",
    "        for title in self.title_list:\n",
    "            page = wikipedia.page(title)\n",
    "            self.corpus.append(preprocessor(page.summary))\n",
    "        \n",
    "        # Get the matrix of word counts for the pages\n",
    "        # this will be the input the the LDA\n",
    "        self.countVectorizer = CountVectorizer(stop_words='english')\n",
    "        self.termFrequency = self.countVectorizer.fit_transform(self.corpus)\n",
    "        self.Words = self.countVectorizer.get_feature_names()\n",
    "        \n",
    "    def Topics(self):\n",
    "        # Obtain the estimates for the LDA model \n",
    "        self.lda = LatentDirichletAllocation(n_components=self.N_topics)\n",
    "        self.lda.fit(self.termFrequency)\n",
    "        \n",
    "        # Obtain the list of the top N_words in the topics\n",
    "        topics = list()\n",
    "        for topic in self.lda.components_:\n",
    "            topics.append([self.Words[i] for i in topic.argsort()[:-self.N_words - 1:-1]])\n",
    "            \n",
    "        # Create a list of column names, Words, for the dataframe output\n",
    "        cols = list()\n",
    "        for i in range(self.N_words):\n",
    "            cols.append(\"Word \"+(str(i)))\n",
    "        \n",
    "        # Create a dataframe with the topic no. and the words in each topic \n",
    "        # output this dataframe\n",
    "        Topics_df = pd.DataFrame(topics, columns = cols)\n",
    "        Topics_df.index.name = \"Topics\"\n",
    "        return Topics_df  \n",
    "    \n",
    "    def Predict_Topics(self, new_title_list):\n",
    "        # Get the new titles for the new pages\n",
    "        # and the number of new pages \n",
    "        self.new_title_list = new_title_list\n",
    "        N_new_docs = len(new_title_list)\n",
    "        \n",
    "        # For each of the new titles get the summary page in Wikipedia\n",
    "        # then obtain the estimate probabilities for each of the topics\n",
    "        # discovered in the training set for each of the new pages\n",
    "        new_doc_topics = list()\n",
    "        for title in self.new_title_list:\n",
    "            new_page = wikipedia.page(title)\n",
    "            new_doc = preprocessor(new_page.summary)\n",
    "            new_doc_topics.append(self.lda.transform(self.countVectorizer.transform([new_doc])))\n",
    "            \n",
    "        # Recast the list of topic probabilities as an array of size number of no. pages X no. of topics\n",
    "        new_doc_topics = np.array(new_doc_topics).reshape(N_new_docs, self.N_topics)\n",
    "        # Create labels for the columns in the output dataframe\n",
    "        cols = list()\n",
    "        for i in range(self.N_topics):\n",
    "            cols.append(\"Topic \"+(str(i)))\n",
    "            \n",
    "        # Create the dataframe whose rows contain the topic probabilities for specific Wikipedia pages\n",
    "        New_Page_df = pd.DataFrame(new_doc_topics, columns = cols )\n",
    "        New_Page_df.insert(0, 'Page Name', self.new_title_list)\n",
    "        return New_Page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poe</td>\n",
       "      <td>novels</td>\n",
       "      <td>published</td>\n",
       "      <td>novel</td>\n",
       "      <td>greene</td>\n",
       "      <td>writer</td>\n",
       "      <td>american</td>\n",
       "      <td>works</td>\n",
       "      <td>literary</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woolf</td>\n",
       "      <td>work</td>\n",
       "      <td>dickens</td>\n",
       "      <td>london</td>\n",
       "      <td>social</td>\n",
       "      <td>literary</td>\n",
       "      <td>fiction</td>\n",
       "      <td>known</td>\n",
       "      <td>novels</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>published</td>\n",
       "      <td>novel</td>\n",
       "      <td>vonnegut</td>\n",
       "      <td>stories</td>\n",
       "      <td>short</td>\n",
       "      <td>novels</td>\n",
       "      <td>american</td>\n",
       "      <td>fitzgerald</td>\n",
       "      <td>literature</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0  Word 1     Word 2   Word 3  Word 4    Word 5    Word 6  \\\n",
       "Topics                                                                      \n",
       "0             poe  novels  published    novel  greene    writer  american   \n",
       "1           woolf    work    dickens   london  social  literary   fiction   \n",
       "2       published   novel   vonnegut  stories   short    novels  american   \n",
       "\n",
       "            Word 7      Word 8      Word 9  \n",
       "Topics                                      \n",
       "0            works    literary  literature  \n",
       "1            known      novels     english  \n",
       "2       fitzgerald  literature       works  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with famous authors\n",
    "\n",
    "authors = ['\"Charles Dickens\"', '\"Graham Greene\"', '\"Jane Eyre\"', '\"Jane Austen\"', '\"George Orwell\"',\n",
    "          '\"Charlotte Bronte\"', '\"Virginia Woolf\"', '\"Evelyn Waugh\"',\n",
    "           '\"Mark Twain\"', '\"Scott Fitzgerald\"','\"Ernest Hemingway\"', '\"William Faulkner\"', \n",
    "          '\"Kurt Vonnegut\"','\"Harper Lee\"', '\"Edgar Allen Poe\"', '\"John Steinbeck\"' ]\n",
    "\n",
    "# This is a small data set, so try 3 topics\n",
    "ld_authors = LDA_wikipedia(title_list = authors, N_topics =3)\n",
    "ld_authors.Topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Name</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Toni Morrison\"</td>\n",
       "      <td>0.625974</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.367068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Stephen King\"</td>\n",
       "      <td>0.573359</td>\n",
       "      <td>0.073148</td>\n",
       "      <td>0.353493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Page Name   Topic 0   Topic 1   Topic 2\n",
       "0  \"Toni Morrison\"  0.625974  0.006958  0.367068\n",
       "1   \"Stephen King\"  0.573359  0.073148  0.353493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how it does with two famous contemporary authors\n",
    "ld_authors.Predict_Topics(['\"Toni Morrison\"', '\"Stephen King\"'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Accident Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.',\n",
       " 'ENGINE 286 CAUGHT FIRE AT THE SPRINGFIELD, MA STATION DUE TO BEARINGS IN MAIN GENERATOR LET GO.',\n",
       " 'TRAIN NO.#4 WITH ENGS 83/11/90/44 AND 11 CARS DERAILED 2 DEADHEAD CARS, C/44834 AND C/9639, WHILE MAKING A SHOVING MOVE ONTO TRACK 28.  THE DERAILMENT WAS DUE TO HIGH BUFF FORCES CAUSED JACKKNIFING OFDEADHEADING AMFLEET CAR 44834 LOCATED DIRECTLY BEHIND ENGINES DUE TO EXCESSIVE AMPERAGE GENERATED BY FOUR P42 LOCOMOTIVES SHOVING TRAIN AGAINST AN APPROXIMATELY 15-POUND BRAKE REDUCTION.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accident narratives are in a json file\n",
    "# Read the JSON file with the narratives and convert to a list for the LDA analysis\n",
    "\n",
    "\n",
    "with open('TrainNarratives.txt') as json_file:  \n",
    "    Narrative_dict = json.load(json_file)\n",
    "    \n",
    "train_reports = list(Narrative_dict.values())\n",
    "    \n",
    "train_reports[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA_trains:\n",
    "    \"\"\"Creates a class for Latent Dirichlet Allocation using summaries from Wikipedia\n",
    "    Input:\n",
    "        reports = list of narratives from accident reports\n",
    "        N_topics = number of topics for LDA to produce\n",
    "        N_words = the number of words to show in a topic\n",
    "        new_report = narrative for a new accident report not in the training set\n",
    "    Methods:\n",
    "        Topics = output the list of topics in the selected narratives\n",
    "        Predict_Topics = Show the predicted probabilities for topics for a new accident narrative\n",
    "            Input: new narrative\n",
    "            \"\"\"\n",
    "    def __init__(self, reports, N_topics=3, N_words = 10):\n",
    "        # the narrative reports\n",
    "        self.reports = reports\n",
    "        # initialize variables\n",
    "        self.N_topics = N_topics\n",
    "        self.N_words = N_words\n",
    "        \n",
    "        # Get the word counts in the reports\n",
    "        self.countVectorizer = CountVectorizer(stop_words='english')\n",
    "        self.termFrequency = self.countVectorizer.fit_transform(self.reports)\n",
    "        self.Words = self.countVectorizer.get_feature_names()\n",
    "        \n",
    "    def Topics(self):\n",
    "                \n",
    "        # Obtain the estimates for the LDA model \n",
    "        self.lda = LatentDirichletAllocation(n_components=self.N_topics)\n",
    "        self.lda.fit(self.termFrequency)\n",
    "        \n",
    "        # Obtain the list of the top N_words in the topics\n",
    "        topics = list()\n",
    "        for topic in self.lda.components_:\n",
    "            topics.append([self.Words[i] for i in topic.argsort()[:-self.N_words - 1:-1]])\n",
    "            \n",
    "        # For each of the topics in the model add the top N_words the list of topics\n",
    "        ### Your code here\n",
    "        # Create column names for the output matrix\n",
    "        cols = list()\n",
    "        for i in range(self.N_words):\n",
    "            cols.append(\"Word \"+(str(i)))\n",
    "            \n",
    "        # Create a dataframe with the topic no. and the words in each topic \n",
    "        # output this dataframe \n",
    "        Topics_df = pd.DataFrame(topics, columns = cols)\n",
    "        Topics_df.index.name = \"Topics\"\n",
    "        return Topics_df\n",
    "    \n",
    "    def Predict_Topics(self, new_reports):\n",
    "        self.new_reports = new_reports\n",
    "        \n",
    "        # Get the list of new accident report narratives\n",
    "        # and the number of new narratives\n",
    "        N_new_reports = len(self.new_reports)\n",
    "        \n",
    "        \n",
    "        # For each of the new narratives \n",
    "        # obtain the estimated probabilities for each of the topics\n",
    "        # in each of the new narratives as estimated by the LDA results\n",
    "        # on the training set \n",
    "        new_report_topics = list()\n",
    "        ### Your code here        \n",
    "        for i in self.new_reports:\n",
    "            new_report_topics.append(self.lda.\\\n",
    "                                     transform(self.countVectorizer.\\\n",
    "                                               transform([i])))\n",
    "        \n",
    "        # Recast the list of probabilities for topics as an array \n",
    "        # of size no. of new reports X no. of topics\n",
    "        new_report_topics = np.array(new_report_topics).\\\n",
    "            reshape(N_new_reports, self.N_topics)\n",
    "        \n",
    "        # Create column names for the output dataframe\n",
    "        cols = list()\n",
    "        ### Your code here        \n",
    "        for i in range(self.N_topics):\n",
    "            cols.append(\"Topic \"+(str(i)))\n",
    "            \n",
    "        # Create the dataframe whose rows contain topic probabilities for \n",
    "        # specificed narratives/reports\n",
    "        ### Your code here\n",
    "        New_Reports_df = pd.DataFrame(new_report_topics, columns = cols)        \n",
    "        New_Page_df.insert(0, 'Reports', self.new_reports)\n",
    "        \n",
    "        return New_Reports_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train = LDA_trains(reports = train_reports, N_topics = 10, N_words = 10)\n",
    "lda_train.reports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damage</td>\n",
       "      <td>track</td>\n",
       "      <td>train</td>\n",
       "      <td>equipment</td>\n",
       "      <td>car</td>\n",
       "      <td>struck</td>\n",
       "      <td>bnsf</td>\n",
       "      <td>locomotive</td>\n",
       "      <td>engine</td>\n",
       "      <td>crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pantograph</td>\n",
       "      <td>wire</td>\n",
       "      <td>catenary</td>\n",
       "      <td>train</td>\n",
       "      <td>shoe</td>\n",
       "      <td>car</td>\n",
       "      <td>causing</td>\n",
       "      <td>damaged</td>\n",
       "      <td>truck</td>\n",
       "      <td>break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>train</td>\n",
       "      <td>yard</td>\n",
       "      <td>west</td>\n",
       "      <td>pulling</td>\n",
       "      <td>north</td>\n",
       "      <td>end</td>\n",
       "      <td>east</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rail</td>\n",
       "      <td>car</td>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>broken</td>\n",
       "      <td>causing</td>\n",
       "      <td>derailment</td>\n",
       "      <td>track</td>\n",
       "      <td>caused</td>\n",
       "      <td>wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>switch</td>\n",
       "      <td>track</td>\n",
       "      <td>train</td>\n",
       "      <td>lined</td>\n",
       "      <td>crew</td>\n",
       "      <td>movement</td>\n",
       "      <td>derailed</td>\n",
       "      <td>yard</td>\n",
       "      <td>cars</td>\n",
       "      <td>conductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cars</td>\n",
       "      <td>track</td>\n",
       "      <td>car</td>\n",
       "      <td>cut</td>\n",
       "      <td>crew</td>\n",
       "      <td>end</td>\n",
       "      <td>lead</td>\n",
       "      <td>rolled</td>\n",
       "      <td>shoved</td>\n",
       "      <td>yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>loads</td>\n",
       "      <td>track</td>\n",
       "      <td>units</td>\n",
       "      <td>ns</td>\n",
       "      <td>tons</td>\n",
       "      <td>empties</td>\n",
       "      <td>car</td>\n",
       "      <td>pulling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>track</td>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>hazardous</td>\n",
       "      <td>materials</td>\n",
       "      <td>released</td>\n",
       "      <td>switch</td>\n",
       "      <td>shoving</td>\n",
       "      <td>yard</td>\n",
       "      <td>pulling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>cars</td>\n",
       "      <td>derailed</td>\n",
       "      <td>emergency</td>\n",
       "      <td>car</td>\n",
       "      <td>went</td>\n",
       "      <td>crew</td>\n",
       "      <td>engineer</td>\n",
       "      <td>mph</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>switch</td>\n",
       "      <td>cars</td>\n",
       "      <td>lead</td>\n",
       "      <td>car</td>\n",
       "      <td>derailed</td>\n",
       "      <td>point</td>\n",
       "      <td>derail</td>\n",
       "      <td>derailing</td>\n",
       "      <td>east</td>\n",
       "      <td>yard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word 0    Word 1    Word 2     Word 3     Word 4    Word 5  \\\n",
       "Topics                                                                   \n",
       "0           damage     track     train  equipment        car    struck   \n",
       "1       pantograph      wire  catenary      train       shoe       car   \n",
       "2         derailed      cars     train       yard       west   pulling   \n",
       "3             rail       car  derailed       cars     broken   causing   \n",
       "4           switch     track     train      lined       crew  movement   \n",
       "5             cars     track       car        cut       crew       end   \n",
       "6         derailed      cars     loads      track      units        ns   \n",
       "7            track  derailed      cars  hazardous  materials  released   \n",
       "8            train      cars  derailed  emergency        car      went   \n",
       "9           switch      cars      lead        car   derailed     point   \n",
       "\n",
       "            Word 6      Word 7  Word 8     Word 9  \n",
       "Topics                                             \n",
       "0             bnsf  locomotive  engine       crew  \n",
       "1          causing     damaged   truck      break  \n",
       "2            north         end    east      track  \n",
       "3       derailment       track  caused      wheel  \n",
       "4         derailed        yard    cars  conductor  \n",
       "5             lead      rolled  shoved       yard  \n",
       "6             tons     empties     car    pulling  \n",
       "7           switch     shoving    yard    pulling  \n",
       "8             crew    engineer     mph      track  \n",
       "9           derail   derailing    east       yard  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.Topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LDA_trains' object has no attribute 'N_new_reports'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f2bce0ff2219>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPredict_Topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_reports\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-2b39745582ae>\u001b[0m in \u001b[0;36mPredict_Topics\u001b[1;34m(self, new_reports)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;31m### Your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN_new_reports\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Topic \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LDA_trains' object has no attribute 'N_new_reports'"
     ]
    }
   ],
   "source": [
    "lda_train.Predict_Topics(train_reports[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reports = train_reports[:3]\n",
    "new_reports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.',\n",
       " 'ENGINE 286 CAUGHT FIRE AT THE SPRINGFIELD, MA STATION DUE TO BEARINGS IN MAIN GENERATOR LET GO.',\n",
       " 'TRAIN NO.#4 WITH ENGS 83/11/90/44 AND 11 CARS DERAILED 2 DEADHEAD CARS, C/44834 AND C/9639, WHILE MAKING A SHOVING MOVE ONTO TRACK 28.  THE DERAILMENT WAS DUE TO HIGH BUFF FORCES CAUSED JACKKNIFING OFDEADHEADING AMFLEET CAR 44834 LOCATED DIRECTLY BEHIND ENGINES DUE TO EXCESSIVE AMPERAGE GENERATED BY FOUR P42 LOCOMOTIVES SHOVING TRAIN AGAINST AN APPROXIMATELY 15-POUND BRAKE REDUCTION.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reports[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
